import string
import unicodedata
from underthesea import text_normalize
from bs4 import BeautifulSoup
import re

def remove_html_tags(text: str) -> str:
    soup = BeautifulSoup(text, "html.parser")
    return soup.get_text()

def clean_text_vn(text: str) -> str:
    text = re.sub(r"[^\w\s_]", " ", text, flags=re.UNICODE)
    return ' '.join(text.split())


def to_lower(text: str) -> str:
    return text.lower()

def standardize_unicode(text: str) -> str:
    return unicodedata.normalize('NFC', text)

def normalize_text(text: str) -> str:
    text = text_normalize(text)
    return text

def stopword_removal(text: str, stopwords: set) -> str:
    words = text.split()
    filtered_words = [word for word in words if word not in stopwords]
    return ' '.join(filtered_words)

def preprocess_text(text: str, stopwords: set) -> str:
    text = remove_html_tags(text)
    text = to_lower(text)
    text = clean_text_vn(text)
    text = standardize_unicode(text)
    text = normalize_text(text)
    
    text = stopword_removal(text, stopwords)
    return text

def has_invalid_char(text):
    return bool(re.search(r"[^\w\s_]", text))

def has_extra_space(text):
    return bool(re.search(r"\s{2,}", text)) or text != text.strip()


